# -*- coding: utf-8 -*-
"""Proyek Akhir.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uiAjcd0neV4b9zuTIoMGPGXzAc4ecTh1
"""

! chmod 600 /content/kaggle.json

! KAGGLE_CONFIG_DIR=/content/ kaggle datasets download -d aprabowo/indonesia-tourism-destination

!unzip /content/indonesia-tourism-destination.zip

# Import library
import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

"""Melakukan import library yang akan digunakan pada model

kita buat variable dengan nama df
"""

df = pd.read_csv('/content/tourism_rating.csv')
df

"""Data rating memiliki 10000 baris dan 3 kolom"""

# Mengubah User_Id menjadi list tanpa nilai yang sama
user_ids = df['User_Id'].unique().tolist()
print('list User_Id: ', user_ids)
     
# Melakukan encoding User_Id
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded User_Id : ', user_to_user_encoded)
     
# Melakukan proses encoding angka ke ke User_Id
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke user_Id: ', user_encoded_to_user)

"""Kita telah mengubah fitur User_Id ke dalam indeks integer """

# Mengubah Place_Id menjadi list tanpa nilai yang sama
tourism_ids = df['Place_Id'].unique().tolist()
     
# Melakukan proses encoding Place_Id
tourism_to_tourism_encoded = {x: i for i, x in enumerate(tourism_ids)}
     
# Melakukan proses encoding angka ke Place_Id
tourism_encoded_to_tourism = {i: x for i, x in enumerate(tourism_ids)}

"""Kita telah mengubah fitur Place_Id ke dalam indeks integer """

# Mapping User_Id ke dataframe user
df['user'] = df['User_Id'].map(user_to_user_encoded)
     
# Mapping Place_Id ke dataframe tourism
df['tourism'] = df['Place_Id'].map(tourism_to_tourism_encoded)

"""Kita telah memetakan User_Id dan Place_Id ke dataframe yang berkaitan"""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)
     
# Mendapatkan jumlah tourism
num_tourism = len(tourism_encoded_to_tourism)
print(num_tourism)
 
# Mengubah rating menjadi nilai float
df['Place_Ratings'] = df['Place_Ratings'].values.astype(np.float32)
     
# Nilai minimum rating
min_rating = min(df['Place_Ratings'])
     
# Nilai maksimal rating
max_rating = max(df['Place_Ratings'])
     
print('Number of User: {}, Number of Tourism: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_tourism, min_rating, max_rating
))

"""Berdasarkan data di atas terdapat 300 jumlah user, 437 jumlah Tourism, dan mengubah nilai rating menjadi float"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

"""Dapat kita lihat bahwa data pada tabel di atas telah di acak """

# Membuat variabel x untuk mencocokkan data user dan tourism menjadi satu value
x = df[['user', 'tourism']].values
     
# Membuat variabel y untuk membuat rating dari hasil 
y = df['Place_Ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
     
# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
     
print(x, y)

"""Kita telah membagi data train dan validasi dengan komposisi 80:20"""

class RecommenderNet(tf.keras.Model):

  # insialisasi fungsi
  def __init__(self, num_users, num_tourism, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_tourism = num_tourism
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.tourism_embedding = layers.Embedding( # layer embeddings resto
        num_tourism,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.tourism_bias = layers.Embedding(num_tourism, 1) # layer embedding resto bias
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    tourism_vector = self.tourism_embedding(inputs[:, 1]) # memanggil layer embedding 3
    tourism_bias = self.tourism_bias(inputs[:, 1]) # memanggil layer embedding 4
 
    dot_user_tourism = tf.tensordot(user_vector, tourism_vector, 2) 
 
    x = dot_user_tourism + user_bias + tourism_bias
    
    return tf.nn.sigmoid(x) # activation sigmoid

"""Membuat class RecommenderNet dengan keras Model class"""

model = RecommenderNet(num_users, num_tourism, 50) #inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Model ini menggunakan Binary Crossentropy untuk menghitung loss function, Adam(Adaptive Moment Estimation) sebagai optimizer, dan root mean squeared error(RMSE) sebagai metrics evalution."""

# Memulai training
     
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""Proses training dilakukan dengan 100 epoch"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Dari proses ini, kita memperoleh nilai error pada data training akhir sebesar sekitar 0.315 dan error pada data validasi sebesar 0.36. Nilai tersebut cukup bagus untuk sistem rekomendasi."""

tourism_df = pd.read_csv('/content/tourism_with_id.csv')
df = pd.read_csv('/content/tourism_rating.csv')

# Mengambil sample user
user_id = df.User_Id.sample(1).iloc[0]
tourism_visited_by_user = df[df.User_Id == user_id]

# Operator bitwise (~), bisa diketetahu di sini  https://docs.python.org/3/reference/expressions.html 
tourism_not_visited = tourism_df[~tourism_df['Place_Id'].isin(tourism_visited_by_user.Place_Id.values)]['Place_Id'] 
tourism_not_visited = list(
    set(tourism_not_visited)
    .intersection(set(tourism_to_tourism_encoded.keys()))
)

tourism_not_visited = [[tourism_to_tourism_encoded.get(x)] for x in tourism_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_resto_array = np.hstack(
    ([[user_encoder]] * len(tourism_not_visited), tourism_not_visited)
)

"""kita telah membuat varibale tourism_not_visited sebagai daftar pariwisata untuk direkomendasikan pada pnegguna"""

ratings = model.predict(user_resto_array).flatten()
     
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_tourism_ids = [
    tourism_encoded_to_tourism.get(tourism_not_visited[x][0]) for x in top_ratings_indices
]
     
print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Tourism with high ratings from user')
print('----' * 8)
     
top_tourism_user = (
    tourism_visited_by_user.sort_values(
        by = 'Place_Ratings',
        ascending=False
    )
    .head(5)
    .Place_Id.values
)
     
tourism_df_rows = tourism_df[tourism_df['Place_Id'].isin(top_tourism_user)]
for row in tourism_df_rows.itertuples():
    print(row.Place_Name, ':', row.Category)
     
print('----' * 8)
print('Top 10 resto recommendation')
print('----' * 8)
     
recommended_tourism = tourism_df[tourism_df['Place_Id'].isin(recommended_resto_ids)]
for row in recommended_tourism.itertuples():
  print(row.Place_Name, ':', row.Category)

"""Rekomendasi untuk user dengan id 154.kita memperoleh 4 rekomendasi pariwisata dengan kategori Taman Hiburan, dan 1 pariwisata dengan kategori Cagar Alam."""